{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from f110_gym.envs.base_classes import Integrator\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix\n",
    "import sys\n",
    "from f110_gym.envs.f110_env import F110Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Tenth_navigation:\n",
    "\n",
    "    def __init__(self,gym_env_code='f110_gym:f110-v0', num_agents=1, map_path=['./f1tenth_racetracks/Austin/Austin_map'], map_ext='.png', sx=0., sy=0., stheta=0., map_centers_file=None, save_path=None, track_name=None, inference=None,reward_file=None,collision_file=None):\n",
    "        '''\n",
    "        F1Tenth_navigation class is used to train the agent on the F110 environment.\n",
    "        Args:\n",
    "            gym_env_code (str): Gym environment code.\n",
    "            num_agents (int): Number of agents in the environment.\n",
    "            map_path (list): List of map paths.\n",
    "            map_ext (str): Map extension.\n",
    "            sx (float): Initial x position of the agent.\n",
    "            sy (float): Initial y position of the agent.\n",
    "            stheta (float): Initial theta position of the agent.\n",
    "            map_centers_file (str): Path to the map centers file.\n",
    "            save_path (str): Path to save the weights and rewards.\n",
    "            track_name (list): List of track names.\n",
    "            inference (str): Path to the inference weights file.\n",
    "            reward_file (str): Path to store the reward file.\n",
    "            collision_file (str): Path to store the time to collison file.\n",
    "        '''\n",
    "\n",
    "        # Environment setup\n",
    "        self.path_counter = 0\n",
    "        self.sx, self.sy, self.stheta = sx, sy, stheta\n",
    "        self.save_path = save_path\n",
    "        self.track_name = track_name\n",
    "        self.num_agents = num_agents\n",
    "        self.map_path = map_path\n",
    "        self.map_ext = map_ext\n",
    "        self.map_centers_file = map_centers_file\n",
    "    \n",
    "        self.env = gym.make(gym_env_code, map=self.map_path[self.path_counter], map_ext=self.map_ext, num_agents=self.num_agents, timestep=0.01, integrator=Integrator.RK4)\n",
    "        self.env.add_render_callback(self.render_callback)\n",
    "       \n",
    "        file = pd.read_csv(self.map_centers_file[self.path_counter])\n",
    "        file.columns = ['x', 'y', 'w_r', 'w_l']\n",
    "        file.index = file.index.astype(int)\n",
    "        self.map_centers = file.values[:, :2]\n",
    "        self.track_width = file.loc[0,'w_r'] + file.loc[0,'w_l']\n",
    "        self.reward_file = reward_file\n",
    "        self.collision_file = collision_file\n",
    "        self.track_center_counter = self.map_centers.shape[0]  # Number of centers in the track\n",
    "\n",
    "        # Random Seed\n",
    "        self.random_seed = 42\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        # Environment Observation Parameters\n",
    "        self.num_beams = 1080\n",
    "        self.n_features = 11\n",
    "        self.angle = 270\n",
    "\n",
    "        # LiDAR downsampling parameters\n",
    "        self.n_sectors = 40\n",
    "        self.normalized_lidar = np.zeros((1,self.n_sectors))\n",
    "\n",
    "        # Action Space Parameters\n",
    "        self.num_angles = self.n_sectors\n",
    "        self.num_speeds = 10\n",
    "\n",
    "\n",
    "        # State Space Parameters\n",
    "        self.num_states = 2 ** self.n_features\n",
    "\n",
    "        # Speed Parameters\n",
    "        self.min_speed = 0.8\n",
    "        self.max_speed = 2\n",
    "\n",
    "        # Action Space\n",
    "        self.angles_deg = np.linspace(-self.angle // 2, self.angle // 2, self.num_angles)[::-1]\n",
    "        self.angles = np.radians(self.angles_deg)\n",
    "        self.speeds = np.linspace(self.min_speed, self.max_speed, self.num_speeds)\n",
    "    \n",
    "        # State Space - Q-Table\n",
    "        if inference is not None:\n",
    "            self.weights = np.load(inference)\n",
    "            self.num_collisions = int(inference.split('_')[-1].split('.')[0])\n",
    "            print(f'Loaded Weights')\n",
    "        else:\n",
    "            self.weights = np.zeros((self.num_states,self.num_angles,self.num_speeds))\n",
    "            self.num_collisions = 0\n",
    "        \n",
    "        self.max_weight = 5\n",
    "\n",
    "        # ELigibility Trace\n",
    "        self.ET = np.zeros((1,self.num_states))\n",
    "        self.IS = np.zeros((self.num_angles,self.num_speeds))\n",
    "\n",
    "        # projection matrix\n",
    "        if self.n_features == 10:\n",
    "            zero_prob = 0.85\n",
    "            one_prob = 0.15\n",
    "        if self.n_features == 11:\n",
    "            zero_prob = 0.8\n",
    "            one_prob = 0.2\n",
    "        self.projection_matrix = self.get_projection_matrix(zero_prob=zero_prob,one_prob=one_prob)\n",
    "\n",
    "        # binary powers\n",
    "        self.binary_powers = np.array([2 ** i for i in range(self.n_features)])\n",
    "\n",
    "        # Training Variables\n",
    "        self.curr_state = None\n",
    "        self.next_state = None\n",
    "        \n",
    "        self.action_threshold_decay = 0.99998\n",
    "        self.action_threshold = 0.25 * (self.action_threshold_decay ** self.num_collisions)\n",
    "\n",
    "        # BTSP Parameters\n",
    "        self.learning_rate = 0.1\n",
    "        self.ET_decay_rate = 0.9\n",
    "        self.IS_decay_rate = 0.7\n",
    "\n",
    "        # Reward\n",
    "        self.reward = 0\n",
    "        self.episode_reward = 0\n",
    "        self.cumulative_reward = 0\n",
    "        self.episodic_rewards = [0]\n",
    "\n",
    "        # Time\n",
    "        self.collision_times = [0]       \n",
    "\n",
    "\n",
    "    def __update_map(self):\n",
    "        '''\n",
    "        Update the map of the environment to the next map in the list.\n",
    "        This function is called after fixed no. of collision with the environment, usually set to 2000 in the training loop.\n",
    "\n",
    "        '''\n",
    "        if self.env.renderer is not None:\n",
    "            self.env.renderer.close()\n",
    "        self.path_counter += 1\n",
    "        if self.path_counter == len(self.map_path):\n",
    "            self.path_counter = 0\n",
    "        self.env.map_name = self.map_path[self.path_counter]\n",
    "        self.env.update_map(f'{self.map_path[self.path_counter]}.yaml',self.map_ext)\n",
    "        F110Env.renderer = None\n",
    "        file = pd.read_csv(self.map_centers_file[self.path_counter])\n",
    "        file.columns = ['x', 'y', 'w_r', 'w_l']\n",
    "        file.index = file.index.astype(int)\n",
    "        self.map_centers = file.values[:, :2]\n",
    "        self.track_width = file.loc[0,'w_r'] + file.loc[0,'w_l']\n",
    "        self.track_center_counter = self.map_centers.shape[0]  # Reset the counter to the number of centers\n",
    "        print(f'Map updated to {self.track_name[self.path_counter]}')\n",
    "        self.logger.info('-------'*20)\n",
    "        self.logger.info(f'Initializing F1Tenth_navigation with map: {self.map_path[self.path_counter]}')\n",
    "        \n",
    "    def render_callback(self, env_renderer):\n",
    "        '''\n",
    "        An inbuilt-function that renders map of the environment.\n",
    "        Render callback function to update the map of the environment.\n",
    "        Do not modify this function.\n",
    "        '''\n",
    "        e = env_renderer\n",
    "        x = e.cars[0].vertices[::2]\n",
    "        y = e.cars[0].vertices[1::2]\n",
    "        top, bottom, left, right = max(y), min(y), min(x), max(x)\n",
    "        e.score_label.x = left\n",
    "        e.score_label.y = top - 700\n",
    "        e.left = left - 800\n",
    "        e.right = right + 800\n",
    "        e.top = top + 800\n",
    "        e.bottom = bottom - 800\n",
    "\n",
    "    def get_statistical_properties(self,lidar_input,n_sectors=None):\n",
    "        '''\n",
    "        Function that is used to downsample the Lidar input.\n",
    "        This function takes the Lidar input and divides it into n_sectors number of sectors.\n",
    "        It then calculates the median of each sector and returns the median values.\n",
    "        Args:\n",
    "            lidar_input (np.ndarray): Lidar input.\n",
    "            n_sectors (int): Number of sectors to downsample the Lidar input into.\n",
    "        '''\n",
    "        assert n_sectors is not None, \"Number of sectors must be provided\"\n",
    "        #  The [100 :-100] is for selecting only those rays corresponding to 220 fov.\n",
    "        sector_size = np.asarray(lidar_input[100:-100],dtype=np.float32).shape[0] // n_sectors\n",
    "        sectors = lidar_input[:sector_size * n_sectors].reshape(n_sectors, sector_size)\n",
    "        return np.median(sectors, axis=1).reshape(1,-1)\n",
    "    \n",
    "    def binarize_vector(self,vector):\n",
    "        '''\n",
    "        Function that is used to binarize the input.\n",
    "        This function takes the projected downsampled-Lidar and binarizes it based on the threshold.\n",
    "        Args:\n",
    "            vector (np.ndarray): Projected downsampled-Lidar input.\n",
    "        Returns:\n",
    "            np.ndarray: Binary represnetation of the Lidar data which is used as a state.\n",
    "        '''\n",
    "\n",
    "        threshold = (np.min(vector)+ np.max(vector))/2\n",
    "        return np.where(vector > threshold, 1, 0)\n",
    "\n",
    "    def get_projection_matrix(self,zero_prob=0.5,one_prob=0.5):\n",
    "        '''\n",
    "        Function that is used to generate the projection matrix.\n",
    "        This function takes the number of features and the number of angles and generates a random projection matrix.\n",
    "        This function is called only once to generate the projection matrix and saves it to a file.\n",
    "        Args:\n",
    "            zero_prob (float): Probability of selecting 0.\n",
    "            one_prob (float): Probability of selecting 1.\n",
    "        Returns:\n",
    "            np.ndarray: Projection matrix.\n",
    "        '''\n",
    "\n",
    "        # Generate a random matrix with values 0 and 1 based on the given probabilities [prob_0,prob_1]\n",
    "        if not os.path.exists('Projection_matrices'):\n",
    "            os.mkdir('Projection_matrices')\n",
    "        if not os.path.exists(os.path.join('Projection_matrices', f'projection_{self.n_features}f_{self.num_angles}a_s{self.random_seed}.npy')):\n",
    "            matrix = np.random.choice([0, 1], size=(self.n_sectors, self.n_features), p=[zero_prob,one_prob])\n",
    "            np.save(os.path.join('Projection_matrices', f'projection_{self.n_features}f_{self.num_angles}a_s{self.random_seed}.npy'), matrix)\n",
    "        else:\n",
    "            matrix = np.load(os.path.join('Projection_matrices', f'projection_{self.n_features}f_{self.num_angles}a_s{self.random_seed}.npy'))\n",
    "        return matrix\n",
    "\n",
    "    def get_binary_representation(self,lidar_input):\n",
    "        '''\n",
    "        Function that is used to get the binary representation of the Lidar input.\n",
    "        This function takes the Lidar input and projects it using the projection matrix.\n",
    "        It then binarizes the projected Lidar input and returns the binary representation.\n",
    "        the bias used is here is some types of non linear projections. It is set to zero here.\n",
    "        Args:\n",
    "            lidar_input (np.ndarray): Lidar input.\n",
    "        Returns:\n",
    "            np.ndarray: Binary representation of the Lidar input.\n",
    "        '''\n",
    "        self.normalized_lidar = normalize(lidar_input,axis=1)\n",
    "        # Do not normalize, just use the raw data\n",
    "        return self.binarize_vector(np.dot(lidar_input,self.projection_matrix))\n",
    "    \n",
    "\n",
    "    def get_state(self, binary):\n",
    "        '''\n",
    "        Function that is used to get the state of the agent.\n",
    "        This function takes the binary representation of the Lidar input and converts it to a state.\n",
    "        Args:\n",
    "            binary (np.ndarray): Binary representation of the Lidar input.\n",
    "        Returns:\n",
    "            int: State of the agent.\n",
    "        '''\n",
    "        return np.dot(binary[0], self.binary_powers)\n",
    "    \n",
    "\n",
    "    def select_action(self, state):\n",
    "        '''\n",
    "        Function that is used to select the action of the agent.\n",
    "        This function takes the state of the agent and selects an action based on the Weight matrix.\n",
    "        The action is selected based on the epsilon greedy policy.\n",
    "        Args:\n",
    "            state (int): State of the agent.\n",
    "        Returns:\n",
    "            tuple: Angle index and speed index of the selected action.\n",
    "        '''\n",
    "        random_number = np.random.rand()\n",
    "        if random_number < self.action_threshold:\n",
    "            angle_index = np.random.randint(0, self.num_angles)\n",
    "            speed_index = np.random.randint(0, self.num_speeds)\n",
    "        else:\n",
    "            max_value = np.max(self.weights[state])\n",
    "            max_indices = np.argwhere(self.weights[state] == max_value)\n",
    "            angle_index, speed_index  = max_indices[np.random.choice(np.arange(len(max_indices)))]\n",
    "        \n",
    "        return angle_index, speed_index\n",
    "\n",
    "    def select_action_inference(self, state):\n",
    "        '''\n",
    "        Function that is used to select the action of the agent during inference.\n",
    "        This function takes the state of the agent and selects an action based on the Weight matrix.\n",
    "        Args:\n",
    "            state (int): State of the agent.\n",
    "        Returns:\n",
    "            tuple: Angle index and speed index of the selected action.\n",
    "        '''\n",
    "        max_indices = np.argwhere(self.weights[state] == np.max(self.weights[state]))\n",
    "        angle_index, speed_index  = max_indices[np.random.choice(np.arange(len(max_indices)))]\n",
    "        return angle_index, speed_index\n",
    "\n",
    "    def BSTP_weight_update(self,angle_idx,speed_idx,point_reward):\n",
    "        '''\n",
    "        The BSTP weight update function is used to update the weights of the agent.The core logic of the BSTP algorithm is implemented here.\n",
    "        The weights are updated based on the eligibility traces and the IS decay.\n",
    "        Args:\n",
    "            angle_idx (int): Angle index of the selected action.\n",
    "            speed_idx (int): Speed index of the selected action.\n",
    "            point_reward (float): Reward received from the environment.\n",
    "        '''\n",
    "        # Using distance at specific location with IS decay\n",
    "        ET_IS_product = (csr_matrix(self.ET).T.dot(self.IS.reshape(1,-1))).reshape(self.num_states,self.num_angles,self.num_speeds)\n",
    "        non_zero_indices = np.argwhere(self.ET!=0)[:,-1]\n",
    "        self.weights[self.curr_state,angle_idx,speed_idx] += point_reward \n",
    "        delta = (self.max_weight - self.weights[non_zero_indices]) * ET_IS_product[non_zero_indices]\n",
    "        np.add(self.weights[non_zero_indices], self.learning_rate * delta, out=self.weights[non_zero_indices])\n",
    "\n",
    "    def set_eligibility_traces(self,angle_idx,speed_idx):\n",
    "        '''\n",
    "        The set eligibility traces function is used to set the eligibility traces of the agent for the location (state,action) it is in currently.\n",
    "        Args:\n",
    "            angle_idx (int): Angle index of the selected action.\n",
    "            speed_idx (int): Speed index of the selected action.\n",
    "        '''\n",
    "        self.ET[0,self.curr_state] = 1\n",
    "        self.IS[angle_idx,speed_idx] = self.normalized_lidar[0,angle_idx]\n",
    "\n",
    "    def decay_eligibility_traces(self):\n",
    "        ''' \n",
    "        The decay eligibility traces function is used to decay the eligibility traces of the agent.\n",
    "        This function decays the eligibility traces based on the decay rate for all the states and action pairs\n",
    "        '''\n",
    "        self.ET *= self.ET_decay_rate\n",
    "        self.IS *= self.IS_decay_rate\n",
    "        self.IS[self.IS < 1e-6] = 0\n",
    "        self.ET[self.ET < 1e-4] = 0\n",
    "\n",
    "    def save_reward_time(self):\n",
    "        '''\n",
    "        Helper function to store the episodic reward and collison times.\n",
    "        '''\n",
    "        if not os.path.exists(os.path.join(self.save_path)):\n",
    "            os.mkdir(os.path.join(self.save_path))\n",
    "        \n",
    "        if self.reward_file is not None:\n",
    "            r = np.append(np.load(self.reward_file), self.episodic_rewards)\n",
    "            t = np.append(np.load(self.collision_file), self.collision_times)\n",
    "            np.save(os.path.join(self.save_path, f'rewards.npy'), np.array(r))\n",
    "            np.save(os.path.join(self.save_path, f'times.npy'), np.array(t))\n",
    "        else:\n",
    "            np.save(os.path.join(self.save_path, f'rewards.npy'), np.array(self.episodic_rewards))\n",
    "            np.save(os.path.join(self.save_path, f'times.npy'), np.array(self.collision_times))\n",
    "\n",
    "    def save_weights(self):\n",
    "        '''\n",
    "        Helper function to store the weights of the agent. \n",
    "        '''\n",
    "        if not os.path.exists(os.path.join(self.save_path)):\n",
    "            os.mkdir(os.path.join(self.save_path))\n",
    "        np.save(os.path.join(self.save_path, f'{self.track_name[self.path_counter]}_{self.num_collisions + 1}.npy'), self.weights)\n",
    "        # print(f'File saved')\n",
    "\n",
    "    def inference(self):\n",
    "        try:\n",
    "            obs, step_reward, done, info = self.env.reset(np.array([[self.sx, self.sy, self.stheta[self.track_name[self.path_counter]]]]))\n",
    "            lidar = obs['scans'][0]\n",
    "            lidar_down_sampled = self.get_statistical_properties(lidar,n_sectors=self.n_sectors)\n",
    "            self.curr_state = self.get_state(self.get_binary_representation(lidar_down_sampled))\n",
    "            angle_index,speed_index = self.select_action_inference(self.curr_state)\n",
    "            while not done:\n",
    "                steering_angle,speed = self.angles[angle_index],self.speeds[speed_index]\n",
    "                obs, step_reward, done, info = self.env.step(np.array([[steering_angle, speed]]))\n",
    "                lidar = obs['scans'][0]\n",
    "                lidar_down_sampled = self.get_statistical_properties(lidar,n_sectors=self.n_sectors)\n",
    "                self.next_state = self.get_state(self.get_binary_representation(lidar_down_sampled))\n",
    "                angle_index,speed_index = self.select_action_inference(self.next_state)\n",
    "                self.curr_state = self.next_state\n",
    "                \n",
    "                self.env.render(mode='human')\n",
    "            raise Exception('Done')\n",
    "        except Exception as e:\n",
    "            print(f'Exception: {e}')\n",
    "            self.env.renderer.close()\n",
    "            self.env.close()\n",
    "            F110Env.renderer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './f1tenth_racetracks'\n",
    "all_map_paths=[]\n",
    "map_centers = []\n",
    "maps = []\n",
    "track_lengths=[]\n",
    "for folder in os.listdir(path):\n",
    "    if folder not in ['README.md','.gitignore','convert.py','LICENSE','rename.py','.git']:\n",
    "        folder_name=folder\n",
    "        file_name=folder_name.replace(' ','')+'_map'\n",
    "        map_center = folder_name.replace(' ','')+'_centerline.csv'\n",
    "        track_lengths.append(len(pd.read_csv(f'{path}/{folder_name}/{map_center}')))\n",
    "        maps.append(folder_name)\n",
    "        all_map_paths.append(f'{path}/{folder_name}/{file_name}')\n",
    "        map_centers.append(f'{path}/{folder_name}/{map_center}')\n",
    "\n",
    "track_length_list = list(zip(maps,track_lengths))\n",
    "track_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_maps = ['Spa','Hockenheim','Shanghai','Nuerburgring','Montreal', 'Austin','Mexico City']\n",
    "test_maps = [i[0] for i in track_length_list if i[0] not in train_maps]\n",
    "print(f'Train Maps: {train_maps}')\n",
    "print(f'Test Maps: {test_maps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global num_agents,map_path,map_ext,sx,sy,stheta,indices\n",
    "num_agents = 1\n",
    "map_ext = '.png'\n",
    "sx = 0.\n",
    "sy = 0.\n",
    "stheta = {'Oschersleben':0, \n",
    "          'BrandsHatch':0.5, \n",
    "          'Monza':1, \n",
    "          'Catalunya':1, \n",
    "          'SaoPaulo':2, \n",
    "          'Sepang':0, \n",
    "          'Silverstone':1, \n",
    "          'YasMarina':0, \n",
    "          'Sochi':1, \n",
    "          'Melbourne':2, \n",
    "          'Budapest':-0.5, \n",
    "          'Spielberg':0, \n",
    "          'Zandvoort':1, \n",
    "          'Sakhir':1, \n",
    "          'MoscowRaceway':1,\n",
    "          'Spa':2, \n",
    "          'Hockenheim':2, \n",
    "          'Shanghai':0, \n",
    "          'Nuerburgring':1, \n",
    "          'Montreal':1.5, \n",
    "          'Austin':-0.5, \n",
    "          'Mexico City':0,\n",
    "          'IMS_map' : -1.0}\n",
    "\n",
    "indices = [idx for idx,i in enumerate(maps) if i in test_maps]\n",
    "# indices = [idx for idx,i in enumerate(maps) if i in train_maps]\n",
    "map_path_subset = [all_map_paths[i] for i in indices]\n",
    "map_centers_subset = [map_centers[i] for i in indices]\n",
    "map_names_subset = [maps[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_file = 'BTSP_220_Multiple_training/Hockenheim_45500.npy'\n",
    "reward_file='BTSP_220_Multiple_training/rewards.npy'\n",
    "collision_file='BTSP_220_Multiple_training/times.npy'\n",
    "\n",
    "map_index = 0\n",
    "\n",
    "map_path = [map_path_subset[map_index]]\n",
    "map_center = [map_centers_subset[map_index]]\n",
    "map_name = [map_names_subset[map_index]]\n",
    "\n",
    "save_path = 'Weights_BTSP/'\n",
    "\n",
    "simulator = F1Tenth_navigation(num_agents=num_agents,map_path=map_path,map_ext=map_ext,sx=sx,sy=sy,stheta=stheta,map_centers_file=map_centers,save_path=save_path,track_name=map_name,inference=inference_file,reward_file=reward_file,collision_file=collision_file)\n",
    "print(f'BTSP Inference on {map_names_subset[map_index]}')\n",
    "simulator.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_file = 'SARSA_220_Multiple_training/Nuerburgring_52000.npy'\n",
    "reward_file='SARSA_220_Multiple_training/rewards.npy'\n",
    "collision_file='SARSA_220_Multiple_training/times.npy'\n",
    "\n",
    "save_path = 'Weights_SARSA/'\n",
    "\n",
    "simulator = F1Tenth_navigation(num_agents=num_agents,map_path=map_path,map_ext=map_ext,sx=sx,sy=sy,stheta=stheta,map_centers_file=map_center,save_path=save_path,track_name=map_name,inference=inference_file,reward_file=reward_file,collision_file=collision_file)\n",
    "print(f'SARSA Inference on {map_names_subset[map_index]}')\n",
    "simulator.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple track inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to run the easy track with no curves\n",
    "inference_file = 'BTSP_220_Multiple_training/Mexico City_35000.npy'\n",
    "# inference_file = 'SARSA_220_Multiple_training/Nuerburgring_52000.npy'\n",
    "reward_file='BTSP_220_Multiple_training/rewards.npy'\n",
    "collision_file='BTSP_220_Multiple_training/times.npy'\n",
    "\n",
    "map_path_subset = ['/home/praneeth/shared_f1_tenth /IMS/IMS_map']\n",
    "map_centers_subset = ['/home/praneeth/shared_f1_tenth /IMS/IMS_centerline.csv']\n",
    "map_names_subset = ['IMS_map']\n",
    "map_index = 0\n",
    "\n",
    "map_path = [map_path_subset[map_index]]\n",
    "map_center = [map_centers_subset[map_index]]\n",
    "map_name = [map_names_subset[map_index]]\n",
    "\n",
    "save_path = 'Weights_BTSP/'\n",
    "\n",
    "simulator = F1Tenth_navigation(num_agents=num_agents,map_path=map_path_subset,map_ext=map_ext,sx=sx,sy=sy,stheta=stheta,map_centers_file=map_centers_subset,save_path=save_path,track_name=map_names_subset,inference=inference_file,reward_file=reward_file,collision_file=collision_file)\n",
    "print(f'BTSP Inference on {map_name}')\n",
    "simulator.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virtual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
